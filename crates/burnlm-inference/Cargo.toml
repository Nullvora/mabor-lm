[package]
name = "burnlm-inference"
edition.workspace = true
version.workspace = true
license.workspace = true
readme.workspace = true

[features]
default = ["tch-gpu"]

# Burn backends
tch-cpu = ["burn/tch"]
tch-gpu = ["burn/tch"]
cuda = ["burn/cuda-jit"]
wgpu = ["burn/wgpu"]

[dependencies]
burn = { workspace = true }
llama-burn = { path = "../../models/llama-burn" }
burnlm-macros = { path = "../burnlm-macros" }

clap = { workspace = true }
gensym = { workspace = true }
inventory = { workspace = true }
once_cell = { workspace = true }
paste = { workspace = true }
serde = { workspace = true }
serde_json = { workspace = true }
strum = { workspace = true }
thiserror = { workspace = true }
tracing = { workspace = true }
tracing-subscriber = { workspace = true }
